{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaKPRhZ5EXT2",
        "outputId": "da10e2f7-9f87-4d2f-f6ab-5de5793178a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#tokenization\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sample1=\"this is a pratice collab book made by me for natutal language processing\""
      ],
      "metadata": {
        "id": "5dZ8zDHbEe7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "tokens=word_tokenize(sample1)"
      ],
      "metadata": {
        "id": "iV_fW7XeEvD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoQgkwJVE4s6",
        "outputId": "02f693ed-8c70-47aa-a9c3-0ca0846ec05a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['this', 'is', 'a', 'pratice', 'collab', 'book', 'made', 'by', 'me', 'for', 'natutal', 'language', 'processing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#stemming\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "Stemmer=PorterStemmer()\n",
        "words=['playing','played','plays']\n",
        "stem_words=[Stemmer.stem(word) for word in words]\n",
        "print(stem_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N54P_KRSFIfu",
        "outputId": "682f414b-e4b5-4489-a8cd-4515053dd02b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['play', 'play', 'play']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#comples words\n",
        "com=['believing','disbelief','unbelievable']\n",
        "stem_com=[Stemmer.stem(word) for word in com]\n",
        "print(stem_com)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to1f6MVYFOxg",
        "outputId": "54ec087e-b383-49ac-8b5d-2a6623eee78c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['believ', 'disbelief', 'unbeliev']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#lemmatization\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import pos_tag,word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "Lemmatizer=WordNetLemmatizer()\n",
        "sentence=\"the leaves on the tree are falling rapidly due to strong wind\"\n",
        "word=word_tokenize(sentence)\n",
        "print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ioLpcPYGYE6",
        "outputId": "009c4c07-1a6d-43b2-ed75-88a5011cec7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'leaves', 'on', 'the', 'tree', 'are', 'falling', 'rapidly', 'due', 'to', 'strong', 'wind']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words=pos_tag(word_tokenize(sentence))\n",
        "print(tagged_words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-heGYGNH0Gj",
        "outputId": "34a6575e-6b0c-4745-998a-6d7a6611da92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 'DT'), ('leaves', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('tree', 'NN'), ('are', 'VBP'), ('falling', 'VBG'), ('rapidly', 'RB'), ('due', 'JJ'), ('to', 'TO'), ('strong', 'JJ'), ('wind', 'NN')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G7dEceF5H_ba"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}